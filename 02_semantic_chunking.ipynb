{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "markdown"
        },
        "id": "9jreCS7Kf7Qp"
      },
      "source": [
        "## 语义分块简介\n",
        "文本分块是检索增强生成（RAG）中的一个关键步骤，其中将大量文本划分为有意义的段落，以提高检索的准确性。与固定长度分块不同，语义分块根据句子之间的内容相似性来分割文本。\n",
        "\n",
        "### 分割点方法：\n",
        "- **百分位数**：找到所有相似性差异的第 X 百分位数，并在下降值大于此值的位置分割块。\n",
        "- **标准差**：在相似性下降超过平均值以下 X 个标准差的位置进行分割。\n",
        "- **四分位距（IQR）**：使用四分位距（Q3 - Q1）来确定分割点。\n",
        "\n",
        "本笔记本实现了三种语义分块方法，并在示例文本上评估**百分位数**方法。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M-hffOPcf7Qs"
      },
      "source": [
        "## 环境配置"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# fitz库需要从pymudf那里安装\n",
        "%pip install --quiet --force-reinstall pymupdf"
      ],
      "metadata": {
        "id": "GMNUPREogYJN",
        "outputId": "c1427708-93c0-46d6-d91e-2749a235a006",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.1/24.1 MB\u001b[0m \u001b[31m68.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "t29wmooWf7Qt"
      },
      "outputs": [],
      "source": [
        "import fitz\n",
        "import os\n",
        "import numpy as np\n",
        "import json\n",
        "from openai import OpenAI"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uDWL6bybf7Qu"
      },
      "source": [
        "## 对提取的文本进行分块\n",
        "在提取文本后，我们将文本分割为更小的、有重叠的部分，以提高检索的准确性。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "y-j5lDVif7Qv",
        "outputId": "3534fe44-2a46-455a-c95e-4254753d7dc2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Understanding Artificial Intelligence \n",
            "Chapter 1: Introduction to Artificial Intelligence \n",
            "Artificial intelligence (AI) refers to the ability of a digital computer or computer-controlled robot \n",
            "to perform tasks commonly associated with intelligent beings. The term is frequently applied to \n",
            "the project of developing systems endowed with the intellectual processes characteristic of \n",
            "humans, such as the ability to reason, discover meaning, generalize, or learn from past \n",
            "experience. Over the past f\n"
          ]
        }
      ],
      "source": [
        "def extract_text_from_pdf(pdf_path):\n",
        "    \"\"\"\n",
        "    从 PDF 文件中抽取文本.\n",
        "\n",
        "    Args:\n",
        "    pdf_path (str): PDF 文件的路径\n",
        "\n",
        "    Returns:\n",
        "    str: 抽取的文本.\n",
        "    \"\"\"\n",
        "    # Open the PDF file\n",
        "    mypdf = fitz.open(pdf_path)\n",
        "    all_text = \"\"  # Initialize an empty string to store the extracted text\n",
        "\n",
        "    # Iterate through each page in the PDF\n",
        "    for page in mypdf:\n",
        "        # Extract text from the current page and add spacing\n",
        "        all_text += page.get_text(\"text\") + \" \"\n",
        "\n",
        "    # Return the extracted text, stripped of leading/trailing whitespace\n",
        "    return all_text.strip()\n",
        "\n",
        "# PDF 文件路径\n",
        "pdf_path = \"./data/AI_Information.pdf\"\n",
        "\n",
        "extracted_text = extract_text_from_pdf(pdf_path)\n",
        "\n",
        "print(extracted_text[:500])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PvKgOtNuf7Qw"
      },
      "source": [
        "## 设置 OpenAI API 客户端"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# colab环境\n",
        "from google.colab import userdata\n",
        "# 使用阿里云百炼平台\n",
        "api_key = userdata.get(\"DASHSCOPE_API_KEY\")\n",
        "base_url = userdata.get(\"DASHSCOPE_BASE_URL\")"
      ],
      "metadata": {
        "id": "x0ivcYpxhbmp"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "zVNAE7rMf7Qx"
      },
      "outputs": [],
      "source": [
        "client = OpenAI(\n",
        "    base_url=base_url,\n",
        "    api_key=api_key\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sT0ygwjkf7Qx"
      },
      "source": [
        "## 创建句子级嵌入\n",
        "我们将文本拆分为句子并生成嵌入。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "1Yvr14Tmf7Qy",
        "outputId": "4e5d9868-48d5-40ff-aff7-96c1bde3c13a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated 257 sentence embeddings.\n"
          ]
        }
      ],
      "source": [
        "def get_embedding(input: str, model: str=\"text-embedding-v2\"):\n",
        "    \"\"\"\n",
        "    使用向量模型为给定的文本创建嵌入向量\n",
        "\n",
        "    Args:\n",
        "    input (str): 输入文本.\n",
        "    model (str): 向量模型名称，默认为dashscope的text-embedding-v2.\n",
        "\n",
        "    Returns:\n",
        "    np.ndarray: The embedding vector.\n",
        "    \"\"\"\n",
        "    response = client.embeddings.create(model=model, input=text)\n",
        "    return np.array(response.data[0].embedding)\n",
        "\n",
        "# 将文本拆分为句子（基础拆分）\n",
        "sentences = extracted_text.split(\". \")\n",
        "\n",
        "# Generate embeddings for each sentence\n",
        "embeddings = [get_embedding(sentence) for sentence in sentences]\n",
        "\n",
        "print(f\"Generated {len(embeddings)} sentence embeddings.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fNT1taduf7Qz"
      },
      "source": [
        "## 计算相似性差异\n",
        "我们计算相邻句子之间的余弦相似度。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "CeZzUbg3f7Qz"
      },
      "outputs": [],
      "source": [
        "def cosine_similarity(vec1, vec2):\n",
        "    \"\"\"\n",
        "    计算两个向量之间的余弦相似度\n",
        "\n",
        "    Args:\n",
        "    vec1 (np.ndarray): 第一个向量.\n",
        "    vec2 (np.ndarray): 第二个向量.\n",
        "\n",
        "    Returns:\n",
        "    float: 两个向量之间的余弦相似度.\n",
        "    \"\"\"\n",
        "    # 计算两个向量的点积，并除以它们范数的乘积\n",
        "    return np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))\n",
        "\n",
        "similarities = [cosine_similarity(embeddings[i], embeddings[i + 1]) for i in range(len(embeddings) - 1)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XKMAeqGEf7Q1"
      },
      "source": [
        "## 实现语义分块\n",
        "我们实现了三种不同的方法来寻找分割点：\n",
        "- **百分位数**：找到所有相似性差异的第 X 百分位数，并在下降值大于此值的位置分割块。\n",
        "- **标准差**：在相似性下降超过平均值以下 X 个标准差的位置进行分割。\n",
        "- **四分位距（IQR）**：使用四分位距（Q3 - Q1）来确定分割点。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "uuITBPxRf7Q1"
      },
      "outputs": [],
      "source": [
        "def compute_breakpoints(similarities, method=\"percentile\", threshold=90):\n",
        "    \"\"\"\n",
        "    根据相似性下降计算分块的分割点。\n",
        "\n",
        "    Args:\n",
        "    similarities (List[float]): 句子两两之间的相似度列表\n",
        "    method (str): 'percentile', 'standard_deviation', or 'interquartile'.\n",
        "    threshold (float): 阈值 (percentile for 'percentile', std devs for 'standard_deviation').\n",
        "\n",
        "    Returns:\n",
        "    List[int]: 分块应该发生的索引位置。\n",
        "    \"\"\"\n",
        "    # 根据 method 决定阈值\n",
        "    if method == \"percentile\":\n",
        "        # 计算相似度分数的第 X 百分位数\n",
        "        threshold_value = np.percentile(similarities, threshold)\n",
        "    elif method == \"standard_deviation\":\n",
        "        # 计算相似度分数的均值和标准差\n",
        "        mean = np.mean(similarities)\n",
        "        std_dev = np.std(similarities)\n",
        "        # 将阈值设置为均值减去 X 个标准差\n",
        "        threshold_value = mean - (threshold * std_dev)\n",
        "    elif method == \"interquartile\":\n",
        "        # 计算第一四分位数和第三四分位数（Q1 和 Q3）\n",
        "        q1, q3 = np.percentile(similarities, [25, 75])\n",
        "        # 使用 IQR 规则设置阈值为四分位距的下限\n",
        "        threshold_value = q1 - 1.5 * (q3 - q1)\n",
        "    else:\n",
        "        # 不支持的方法\n",
        "        raise ValueError(\"Invalid method. Choose 'percentile', 'standard_deviation', or 'interquartile'.\")\n",
        "\n",
        "    # 识别相似度下降低于阈值的索引\n",
        "    return [i for i, sim in enumerate(similarities) if sim < threshold_value]\n",
        "\n",
        "breakpoints = compute_breakpoints(similarities, method=\"percentile\", threshold=90)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hciPcuw0f7Q2"
      },
      "source": [
        "## 将文本分割成语义块\n",
        "我们根据计算出的分割点将文本分割成块。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "EVr2dEIEf7Q2",
        "outputId": "cfc1120a-fb90-45c4-bf90-b11aaae1fc5f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of semantic chunks: 231\n",
            "\n",
            "First text chunk:\n",
            "Understanding Artificial Intelligence \n",
            "Chapter 1: Introduction to Artificial Intelligence \n",
            "Artificial intelligence (AI) refers to the ability of a digital computer or computer-controlled robot \n",
            "to perform tasks commonly associated with intelligent beings.\n"
          ]
        }
      ],
      "source": [
        "def split_into_chunks(sentences, breakpoints):\n",
        "    \"\"\"\n",
        "    分割句子为语义块。\n",
        "\n",
        "    Args:\n",
        "    sentences (List[str]): 句子列表\n",
        "    breakpoints (List[int]): 要进行分割的索引.\n",
        "\n",
        "    Returns:\n",
        "    List[str]: 文本块列表.\n",
        "    \"\"\"\n",
        "    chunks = []\n",
        "    start = 0  # 开始索引\n",
        "\n",
        "    # 迭代每个分割点\n",
        "    for bp in breakpoints:\n",
        "        # 将从起始位置到当前分割点的句子块追加到列表中\n",
        "        chunks.append(\". \".join(sentences[start:bp + 1]) + \".\")\n",
        "        start = bp + 1  # 将开始索引更新为分割点之后的下一个句子\n",
        "\n",
        "    # 将剩余的句子作为最后一个块追加\n",
        "    chunks.append(\". \".join(sentences[start:]))\n",
        "    return chunks\n",
        "\n",
        "text_chunks = split_into_chunks(sentences, breakpoints)\n",
        "\n",
        "# Print the number of chunks created\n",
        "print(f\"Number of semantic chunks: {len(text_chunks)}\")\n",
        "\n",
        "# Print the first chunk to verify the result\n",
        "print(\"\\nFirst text chunk:\")\n",
        "print(text_chunks[0])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "erw8MfqSf7Q2"
      },
      "source": [
        "## 为语义块创建嵌入\n",
        "我们为每个块创建嵌入，以便后续检索。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "oP2rOA1Lf7Q3"
      },
      "outputs": [],
      "source": [
        "def create_embeddings(text_chunks: list[str]):\n",
        "    \"\"\"\n",
        "    为每个文本块创建嵌入。\n",
        "\n",
        "    Args:\n",
        "    text_chunks (List[str]): 文本块列表.\n",
        "\n",
        "    Returns:\n",
        "    List[np.ndarray]: 嵌入向量列表.\n",
        "    \"\"\"\n",
        "    return [get_embedding(chunk) for chunk in text_chunks]\n",
        "\n",
        "chunk_embeddings = create_embeddings(text_chunks)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ii6oRHIf7Q3"
      },
      "source": [
        "## 执行语义搜索\n",
        "我们实现余弦相似度，以检索最相关的块。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "0VmcyJkDf7Q3"
      },
      "outputs": [],
      "source": [
        "def semantic_search(query, text_chunks, chunk_embeddings, k=5):\n",
        "    \"\"\"\n",
        "    根据查询找到最相关的文本块\n",
        "\n",
        "    Args:\n",
        "    query (str): 查询.\n",
        "    text_chunks (List[str]): 文本块列表.\n",
        "    chunk_embeddings (List[np.ndarray]): 文本块嵌入向量列表.\n",
        "    k (int): 要返回的最相关结果的数量.\n",
        "\n",
        "    Returns:\n",
        "    List[str]: Top-k 相关文本块.\n",
        "    \"\"\"\n",
        "    # 创建查询的嵌入向量\n",
        "    query_embedding = get_embedding(query)\n",
        "\n",
        "    # 计算文本块与查询的余弦相似度\n",
        "    similarities = [cosine_similarity(query_embedding, emb) for emb in chunk_embeddings]\n",
        "\n",
        "    # 获取最相似的 k 个块的索引\n",
        "    # 递增排序，所以是-k\n",
        "    # 最后要反转成递减\n",
        "    top_indices = np.argsort(similarities)[-k:][::-1]\n",
        "\n",
        "    return [text_chunks[i] for i in top_indices]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "0ERflR6Xf7Q4",
        "outputId": "e83e4d40-0687-4392-e19f-68d656145cf2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: What is 'Explainable AI' and why is it considered important?\n",
            "Context 1:\n",
            "\n",
            "Explainable AI (XAI) \n",
            "Explainable AI (XAI) aims to make AI systems more transparent and understandable. Research in \n",
            "XAI focuses on developing methods for explaining AI decisions, enhancing trust, and improving \n",
            "accountability.\n",
            "========================================\n",
            "Context 2:\n",
            "\n",
            "Transparency and Explainability \n",
            "Transparency and explainability are essential for building trust in AI systems. Explainable AI (XAI) \n",
            "techniques aim to make AI decisions more understandable, enabling users to assess their \n",
            "fairness and accuracy.\n",
            "========================================\n"
          ]
        }
      ],
      "source": [
        "# 加载验证数据集\n",
        "with open('./data/val.json') as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "# 使用第一个问题\n",
        "query = data[0]['question']\n",
        "\n",
        "top_chunks = semantic_search(query, text_chunks, chunk_embeddings, k=2)\n",
        "\n",
        "# Print the query\n",
        "print(f\"Query: {query}\")\n",
        "\n",
        "# Print the top 2 most relevant text chunks\n",
        "for i, chunk in enumerate(top_chunks):\n",
        "    print(f\"Context {i+1}:\\n{chunk}\\n{'='*40}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2NFdr6Iff7Q5"
      },
      "source": [
        "## 基于检索到的块生成响应"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "vfylgrb3f7Q5"
      },
      "outputs": [],
      "source": [
        "system_prompt = \"You are an AI assistant that strictly answers based on the given context. If the answer cannot be derived directly from the provided context, respond with: 'I do not have enough information to answer that.'\"\n",
        "\n",
        "def generate_response(system_prompt, user_message, model=\"qwen2.5-7b-instruct-1m\"):\n",
        "    \"\"\"\n",
        "    根据 system prompt 和 user message 从 AI 模型生成响应。\n",
        "\n",
        "    Args:\n",
        "    system_prompt (str): system prompt\n",
        "    user_message (str): 用户消息或查询\n",
        "    model (str): LLM, 默认为qwen2.5-7b-instruct-1m.\n",
        "\n",
        "    Returns:\n",
        "    dict: AI 模型响应\n",
        "    \"\"\"\n",
        "    response = client.chat.completions.create(\n",
        "        model=model,\n",
        "        temperature=0,\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": system_prompt},\n",
        "            {\"role\": \"user\", \"content\": user_message}\n",
        "        ]\n",
        "    )\n",
        "    return response\n",
        "\n",
        "# 根据最相关的块创建用户提示\n",
        "user_prompt = \"\\n\".join([f\"Context {i + 1}:\\n{chunk}\\n=====================================\\n\" for i, chunk in enumerate(top_chunks)])\n",
        "user_prompt = f\"{user_prompt}\\nQuestion: {query}\"\n",
        "\n",
        "ai_response = generate_response(system_prompt, user_prompt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fZ9S_rRqf7Q6"
      },
      "source": [
        "## 评估 AI 响应\n",
        "我们将 AI 响应与预期答案进行比较，并分配一个分数。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "2C5sSDhif7Q6",
        "outputId": "8f486d6a-548b-4f79-f2f0-d028f2461dcb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Score: 1\n",
            "\n",
            "Explanation: The AI response accurately captures the essence of Explainable AI (XAI), mentioning its goals of transparency and understanding, as well as its importance for trust, accountability, and fairness. The response closely aligns with the true response without any significant discrepancies, making it very close in meaning and scope. Therefore, a score of 1 is appropriate.\n"
          ]
        }
      ],
      "source": [
        "# 评估用的 system prompt\n",
        "evaluate_system_prompt = \"You are an intelligent evaluation system tasked with assessing the AI assistant's responses. If the AI assistant's response is very close to the true response, assign a score of 1. If the response is incorrect or unsatisfactory in relation to the true response, assign a score of 0. If the response is partially aligned with the true response, assign a score of 0.5.\"\n",
        "\n",
        "# 通过组合 query 、AI respone、真实响应和 system prompt 来创建评估提示\n",
        "evaluation_prompt = f\"User Query: {query}\\nAI Response:\\n{ai_response.choices[0].message.content}\\nTrue Response: {data[0]['ideal_answer']}\\n{evaluate_system_prompt}\"\n",
        "\n",
        "evaluation_response = generate_response(evaluate_system_prompt, evaluation_prompt)\n",
        "\n",
        "print(evaluation_response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eL2_qS9pxdo3"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv-new-specific-rag",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}