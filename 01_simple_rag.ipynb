{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "markdown"
        },
        "id": "baXcTmI1urF4"
      },
      "source": [
        "# 简单 RAG 介绍\n",
        "\n",
        "检索增强生成（RAG）是一种混合方法，结合了信息检索和生成模型。它通过整合外部知识来提升语言模型的性能，从而提高准确性和事实正确性。\n",
        "\n",
        "在简单 RAG 设置中，我们遵循以下步骤：\n",
        "\n",
        "1. **数据摄取**：加载和预处理文本数据。\n",
        "2. **分块**：将数据拆分成更小的块，以提高检索性能。\n",
        "3. **嵌入创建**：使用嵌入模型将文本块转换为数值表示。\n",
        "4. **语义搜索**：根据用户查询检索相关块。\n",
        "5. **响应生成**：使用语言模型根据检索到的文本生成响应。\n",
        "\n",
        "本笔记本实现了简单 RAG 方法，评估了模型的响应，并探索了各种改进方法。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dNY18dOcurF5"
      },
      "source": [
        "## 环境设置\n",
        "安装并导入必要的库"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# fitz库需要从pymudf那里安装\n",
        "%pip install --quiet --force-reinstall pymupdf"
      ],
      "metadata": {
        "id": "CJUWFQLUvg9P",
        "outputId": "d5a7d76b-2637-4e2f-b1f1-ad3f0bc69817",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.1/24.1 MB\u001b[0m \u001b[31m45.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "eJWw-Mz5urF6"
      },
      "outputs": [],
      "source": [
        "import fitz\n",
        "import os\n",
        "import numpy as np\n",
        "import json\n",
        "from openai import OpenAI"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kibCn4baurF6"
      },
      "source": [
        "## 从 PDF 文件中提取文本\n",
        "\n",
        "要实现 RAG，我们首先需要一个文本数据源。在本例中，我们使用 PyMuPDF 库（也被称为 fitz ）从 PDF 文件中提取文本。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "2yzDdRZjurF6"
      },
      "outputs": [],
      "source": [
        "def extract_text_from_pdf(pdf_path: str):\n",
        "    \"\"\"\n",
        "    从 PDF 文件中提取文本并打印前 `num_chars` 个字符。\n",
        "\n",
        "    Args:\n",
        "    pdf_path (str): PDF 文件的路径。\n",
        "\n",
        "    Returns:\n",
        "    str: 从 PDF 中提取的文本。\n",
        "    \"\"\"\n",
        "    # 打开 PDF 文件\n",
        "    mypdf = fitz.open(pdf_path)\n",
        "    all_text = \"\"  # 初始化一个空字符串来存储提取的文本\n",
        "\n",
        "    # 遍历 PDF 中的每一页\n",
        "    for page_num in range(mypdf.page_count):\n",
        "        page = mypdf[page_num]  # 获取页面\n",
        "        text = page.get_text(\"text\")  # 提取页面的文本\n",
        "        all_text += text  # 将提取的文本追加到 `all_text` 字符串中\n",
        "\n",
        "    return all_text  # 返回提取的文本"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vPdAgqyYurF7"
      },
      "source": [
        "## 对提取的文本进行分块\n",
        "在提取文本后，我们将文本分割为更小的、有重叠的部分，以提高检索的准确性。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "0OOMqAXDurF7"
      },
      "outputs": [],
      "source": [
        "def chunk_text(text: str, n: int, overlap: int):\n",
        "    \"\"\"\n",
        "    将给定的文本分割成具有重叠的 n 个字符的段。\n",
        "\n",
        "    Args:\n",
        "    text (str): 要被分块的文本\n",
        "    n (int): 每个分块的字符数量.\n",
        "    overlap (int): 分块之间重叠的字符数量.\n",
        "\n",
        "    Returns:\n",
        "    List[str]: 文本分块列表.\n",
        "    \"\"\"\n",
        "    chunks = []  # 初始化一个空列表来存储分块的内容。\n",
        "\n",
        "    # 以 (n - overlap) 为步长遍历文本。\n",
        "    for i in range(0, len(text), n - overlap):\n",
        "        # 将从索引 i 到 i + n 的文本块追加到 chunks 列表中\n",
        "        chunks.append(text[i:i + n])\n",
        "\n",
        "    return chunks  # 返回文本分块列表"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VjGp8hsRurF7"
      },
      "source": [
        "## 设置 OpenAI API 客户端\n",
        "我们初始化 OpenAI 客户端以生成嵌入和响应。"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# colab环境\n",
        "from google.colab import userdata\n",
        "# 使用阿里云百炼平台\n",
        "api_key = userdata.get(\"DASHSCOPE_API_KEY\")\n",
        "base_url = userdata.get(\"DASHSCOPE_BASE_URL\")"
      ],
      "metadata": {
        "id": "bx2zQw9kzCor"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "7EOZ9icAurF7"
      },
      "outputs": [],
      "source": [
        "client = OpenAI(\n",
        "    base_url=base_url,\n",
        "    api_key=api_key\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SDtO4jBLurF7"
      },
      "source": [
        "## 从 PDF 文件中提取和分块文本\n",
        "现在，我们加载 PDF 文件，提取文本并将其分割成块。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "NFHX3T7MurF7",
        "outputId": "d1ff6a8a-1526-463b-9170-4940f1589726",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of text chunks: 42\n",
            "\n",
            "First text chunk:\n",
            "Understanding Artificial Intelligence \n",
            "Chapter 1: Introduction to Artificial Intelligence \n",
            "Artificial intelligence (AI) refers to the ability of a digital computer or computer-controlled robot \n",
            "to perform tasks commonly associated with intelligent beings. The term is frequently applied to \n",
            "the project of developing systems endowed with the intellectual processes characteristic of \n",
            "humans, such as the ability to reason, discover meaning, generalize, or learn from past \n",
            "experience. Over the past few decades, advancements in computing power and data availability \n",
            "have significantly accelerated the development and deployment of AI. \n",
            "Historical Context \n",
            "The idea of artificial intelligence has existed for centuries, often depicted in myths and fiction. \n",
            "However, the formal field of AI research began in the mid-20th century. The Dartmouth Workshop \n",
            "in 1956 is widely considered the birthplace of AI. Early AI research focused on problem-solving \n",
            "and symbolic methods. The 1980s saw a rise in exp\n"
          ]
        }
      ],
      "source": [
        "# pdf文件地址（colab要上传）\n",
        "pdf_path = \"./data/AI_Information.pdf\"\n",
        "\n",
        "# 提取文本\n",
        "extracted_text = extract_text_from_pdf(pdf_path)\n",
        "\n",
        "# 将提取的文本分割成具有 200 个字符重叠的 1000 个字符的分块。\n",
        "text_chunks = chunk_text(extracted_text, 1000, 200)\n",
        "\n",
        "# 打印分块数量\n",
        "print(\"Number of text chunks:\", len(text_chunks))\n",
        "\n",
        "print(\"\\nFirst text chunk:\")\n",
        "print(text_chunks[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b59HYHGourF8"
      },
      "source": [
        "## 为文本块创建嵌入\n",
        "嵌入将文本转换为数值向量，从而可以高效地进行相似性搜索。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "KqVV2S3lurF8"
      },
      "outputs": [],
      "source": [
        "def create_embeddings(text, model=\"text-embedding-v2\"):\n",
        "    \"\"\"\n",
        "    Creates embeddings for the given text using the specified OpenAI model.\n",
        "    使用向量模型为给定的文本创建嵌入向量\n",
        "\n",
        "    Args:\n",
        "    text (str): 需要创建嵌入向量的文本\n",
        "    model (str): 向量模型，默认是dashscope的`text-embedding-v2`\n",
        "\n",
        "    Returns:\n",
        "    dict: 来自 OpenAI API 的响应，包含嵌入。\n",
        "    \"\"\"\n",
        "    response = client.embeddings.create(\n",
        "        model=model,\n",
        "        input=text,\n",
        "    )\n",
        "\n",
        "    return response\n",
        "\n",
        "def batch_read(lst, batch_size=10):\n",
        "  for i in range(0, len(lst), batch_size):\n",
        "        yield lst[i:i + batch_size]\n",
        "\n",
        "response = None\n",
        "\n",
        "for batch in batch_read(text_chunks):\n",
        "  if not response:\n",
        "    response = create_embeddings(batch)\n",
        "  else:\n",
        "    response.data.extend(create_embeddings(batch).data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qFgcLmDourF8"
      },
      "source": [
        "## 执行语义搜索\n",
        "我们实现余弦相似度，以找到与用户查询最相关的文本块。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "pzHpobMCurF8"
      },
      "outputs": [],
      "source": [
        "def cosine_similarity(vec1, vec2):\n",
        "    \"\"\"\n",
        "    计算两个向量之间的余弦相似度\n",
        "\n",
        "    Args:\n",
        "    vec1 (np.ndarray): 第一个向量.\n",
        "    vec2 (np.ndarray): 第二个向量.\n",
        "\n",
        "    Returns:\n",
        "    float: 两个向量之间的余弦相似度.\n",
        "    \"\"\"\n",
        "    # 计算两个向量的点积，并除以它们范数的乘积\n",
        "    return np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "IqihkvqkurF8"
      },
      "outputs": [],
      "source": [
        "def semantic_search(query, text_chunks, embeddings, k=5):\n",
        "    \"\"\"\n",
        "    使用给定的查询和嵌入对文本块执行语义搜索。\n",
        "\n",
        "    Args:\n",
        "    query (str): 语义搜索的查询\n",
        "    text_chunks (List[str]): 要进行检索的文本块列表\n",
        "    embeddings (List[dict]): 文本块对应的嵌入向量列表.\n",
        "    k (int): 要返回的最相关的文本块的数量，默认为 5.\n",
        "\n",
        "    Returns:\n",
        "    List[str]: 基于查询的最相关的 k 个文本块的列表.\n",
        "    \"\"\"\n",
        "    # 创建查询的嵌入向量\n",
        "    query_embedding = create_embeddings(query).data[0].embedding\n",
        "    similarity_scores = []  # 初始化相似度列表\n",
        "\n",
        "    # 计算查询嵌入与每个文本块嵌入之间的相似度分数\n",
        "    for i, chunk_embedding in enumerate(embeddings):\n",
        "        similarity_score = cosine_similarity(np.array(query_embedding), np.array(chunk_embedding.embedding))\n",
        "        similarity_scores.append((i, similarity_score))\n",
        "\n",
        "    # 降序排序\n",
        "    similarity_scores.sort(key=lambda x: x[1], reverse=True)\n",
        "    # 获取最相似的 k 个文本块的索引\n",
        "    top_indices = [index for index, _ in similarity_scores[:k]]\n",
        "\n",
        "    return [text_chunks[index] for index in top_indices]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CNE87K6TurF8"
      },
      "source": [
        "## 在提取的文本块上运行查询"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "p3xtfn5furF9",
        "outputId": "2968bb43-b085-4f53-f83f-f302db9f2efe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: What is 'Explainable AI' and why is it considered important?\n",
            "Context 1:\n",
            "systems. Explainable AI (XAI) \n",
            "techniques aim to make AI decisions more understandable, enabling users to assess their \n",
            "fairness and accuracy. \n",
            "Privacy and Data Protection \n",
            "AI systems often rely on large amounts of data, raising concerns about privacy and data \n",
            "protection. Ensuring responsible data handling, implementing privacy-preserving techniques, \n",
            "and complying with data protection regulations are crucial. \n",
            "Accountability and Responsibility \n",
            "Establishing accountability and responsibility for AI systems is essential for addressing potential \n",
            "harms and ensuring ethical behavior. This includes defining roles and responsibilities for \n",
            "developers, deployers, and users of AI systems. \n",
            "Chapter 20: Building Trust in AI \n",
            "Transparency and Explainability \n",
            "Transparency and explainability are key to building trust in AI. Making AI systems understandable \n",
            "and providing insights into their decision-making processes helps users assess their reliability \n",
            "and fairness. \n",
            "Robustness and Reliability \n",
            "\n",
            "=====================================\n",
            "Context 2:\n",
            "nt aligns with societal values. Education and awareness campaigns inform the public \n",
            "about AI, its impacts, and its potential. \n",
            "Chapter 19: AI and Ethics \n",
            "Principles of Ethical AI \n",
            "Ethical AI principles guide the development and deployment of AI systems to ensure they are fair, \n",
            "transparent, accountable, and beneficial to society. Key principles include respect for human \n",
            "rights, privacy, non-discrimination, and beneficence. \n",
            " \n",
            " \n",
            "Addressing Bias in AI \n",
            "AI systems can inherit and amplify biases present in the data they are trained on, leading to unfair \n",
            "or discriminatory outcomes. Addressing bias requires careful data collection, algorithm design, \n",
            "and ongoing monitoring and evaluation. \n",
            "Transparency and Explainability \n",
            "Transparency and explainability are essential for building trust in AI systems. Explainable AI (XAI) \n",
            "techniques aim to make AI decisions more understandable, enabling users to assess their \n",
            "fairness and accuracy. \n",
            "Privacy and Data Protection \n",
            "AI systems often rely on la\n",
            "=====================================\n"
          ]
        }
      ],
      "source": [
        "# 导入验证数据\n",
        "with open('./data/val.json') as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "# 从验证数据中提取第一个查询\n",
        "query = data[0]['question']\n",
        "\n",
        "# 执行语义搜索，以找到与查询最相关的前 2 个文本块\n",
        "top_chunks = semantic_search(query, text_chunks, response.data, k=2)\n",
        "\n",
        "print(\"Query:\", query)\n",
        "\n",
        "# 打印文本块\n",
        "for i, chunk in enumerate(top_chunks):\n",
        "    print(f\"Context {i + 1}:\\n{chunk}\\n=====================================\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9OHnOeHQurF9"
      },
      "source": [
        "## 基于检索到的块生成响应"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "1nc-8TcturF9"
      },
      "outputs": [],
      "source": [
        "system_prompt = \"You are an AI assistant that strictly answers based on the given context. If the answer cannot be derived directly from the provided context, respond with: 'I do not have enough information to answer that.'\"\n",
        "\n",
        "def generate_response(system_prompt, user_message, model=\"qwen2.5-7b-instruct-1m\"):\n",
        "    \"\"\"\n",
        "    根据 system prompt 和 user message 从 AI 模型生成响应。\n",
        "\n",
        "    Args:\n",
        "    system_prompt (str): system prompt\n",
        "    user_message (str): 用户消息或查询\n",
        "    model (str): LLM, 默认为qwen2.5-7b-instruct-1m.\n",
        "\n",
        "    Returns:\n",
        "    dict: AI 模型响应\n",
        "    \"\"\"\n",
        "    response = client.chat.completions.create(\n",
        "        model=model,\n",
        "        temperature=0,\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": system_prompt},\n",
        "            {\"role\": \"user\", \"content\": user_message}\n",
        "        ]\n",
        "    )\n",
        "    return response\n",
        "\n",
        "# 根据最相关的块创建用户提示\n",
        "user_prompt = \"\\n\".join([f\"Context {i + 1}:\\n{chunk}\\n=====================================\\n\" for i, chunk in enumerate(top_chunks)])\n",
        "user_prompt = f\"{user_prompt}\\nQuestion: {query}\"\n",
        "\n",
        "ai_response = generate_response(system_prompt, user_prompt, model=\"qwen-turbo\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hEFqyOTHurF9"
      },
      "source": [
        "## 评估 AI 响应\n",
        "我们将 AI 响应与预期答案进行比较，并分配一个分数。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "zIoTHYhxurF9",
        "outputId": "56eb2935-fe5c-426a-b7f8-775413f04a61",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Score: 1\n",
            "\n",
            "The AI response accurately captures the essence of Explainable AI (XAI), its definition, and its importance as stated in the true response. The explanation about building trust, accountability, ensuring fairness, and aligning with ethical standards is spot-on and closely matches the true response. There are no inaccuracies or significant omissions in the AI's response.\n"
          ]
        }
      ],
      "source": [
        "# 评估用的 system prompt\n",
        "evaluate_system_prompt = \"You are an intelligent evaluation system tasked with assessing the AI assistant's responses. If the AI assistant's response is very close to the true response, assign a score of 1. If the response is incorrect or unsatisfactory in relation to the true response, assign a score of 0. If the response is partially aligned with the true response, assign a score of 0.5.\"\n",
        "\n",
        "# 通过组合 query 、AI respone、真实响应和 system prompt 来创建评估提示\n",
        "evaluation_prompt = f\"User Query: {query}\\nAI Response:\\n{ai_response.choices[0].message.content}\\nTrue Response: {data[0]['ideal_answer']}\\n{evaluate_system_prompt}\"\n",
        "\n",
        "evaluation_response = generate_response(evaluate_system_prompt, evaluation_prompt)\n",
        "\n",
        "print(evaluation_response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "neXm4JZjDFKf"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv-new-specific-rag",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}